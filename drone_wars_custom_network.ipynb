{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"drone_wars_custom_network.ipynb","provenance":[{"file_id":"1wM_eKjtGmzTRnxC2dnjSnZ6K_KGkNM4h","timestamp":1658416003455}],"collapsed_sections":[],"authorship_tag":"ABX9TyN9PP7zfKBFiHNAMnrzveuA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BH0SCpRjE-uF","executionInfo":{"status":"ok","timestamp":1658418843326,"user_tz":420,"elapsed":13466,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}},"outputId":"74e317bc-1485-4f1c-83ae-5e9b331fa768"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pygame\n","  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n","\u001b[?25hInstalling collected packages: pygame\n","Successfully installed pygame-2.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting stable_baselines3\n","  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 4.1 MB/s \n","\u001b[?25hCollecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.2.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.12.0+cu113)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.5)\n","Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable_baselines3) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (4.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable_baselines3) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2022.1)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616823 sha256=17a795d25ba4ec418c1626ac2d8e69265b0319a304c4e7af51d92057a487ecc0\n","  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n","Successfully built gym\n","Installing collected packages: gym, stable-baselines3\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","Successfully installed gym-0.21.0 stable-baselines3-1.6.0\n"]}],"source":["!pip install pygame\n","!pip install stable_baselines3"]},{"cell_type":"code","source":["import pygame\n","import random\n","import numpy as np\n","#np.set_printoptions(threshold=np.inf)\n","from pygame.surfarray import array3d\n","import torch\n","import cv2\n","import gym \n","from gym import spaces \n","from stable_baselines3 import DQN\n","import os\n","import pickle\n","from stable_baselines3.common.utils import polyak_update\n"],"metadata":{"id":"FzlSqQJXFJmp","executionInfo":{"status":"ok","timestamp":1658419152058,"user_tz":420,"elapsed":327,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Required to fool the system that there is a video output\n","os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\" "],"metadata":{"id":"aRzJzGoGcZN4","executionInfo":{"status":"ok","timestamp":1658418855700,"user_tz":420,"elapsed":200,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Drone class\n","class Drone:\n","    def __init__(self, gameDisplay, display_width=800, display_height=600, *args, **kwargs):\n","        self.drone_speed = 20 # Default rate of change for drone movement\n","        self.x_change = 0\n","        self.y_change = 0\n","        self.x = 0\n","        self.y = 0\n","        self.drone_width = 70 # 35\n","        self.drone_height = 70 # 35\n","        self.display_width = display_width\n","        self.display_height = display_height\n","        self.gameDisplay = gameDisplay\n","        self.img = pygame.image.load('images/drone1.png').convert() # To fix up png files use: pngcrush -ow -rem allb -reduce file.png\n","        self.img = pygame.transform.scale(self.img, (int(self.display_width*0.1),int(self.display_height*0.12)))\n","        #self.img = pygame.transform.scale(self.img, (int(self.display_width*0.05),int(self.display_height*0.06)))\n","\n","    def move_left(self):\n","        self.x_change = -self.drone_speed\n","\n","    def move_right(self):\n","        self.x_change = self.drone_speed\n","\n","    def move_up(self):\n","        self.y_change = -self.drone_speed\n","\n","    def move_down(self):\n","        self.y_change = +self.drone_speed\n","\n","    def update(self):\n","        self.x += self.x_change\n","        self.y += self.y_change\n","        self.x_change = 0\n","        self.y_change = 0\n","\n","    def draw(self):\n","        self.gameDisplay.blit(self.img, (self.x,self.y))\n"],"metadata":{"id":"R5R2bjhgFrD9","executionInfo":{"status":"ok","timestamp":1658418857470,"user_tz":420,"elapsed":156,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Obstacle class\n","class Obstacle:\n","    def __init__(self, gameDisplay, display_width=800, display_height=600, *args, **kwargs):\n","        #self.x = 0\n","        #self.y = 0\n","        self.x = random.randrange(0, display_width)\n","        self.y = -100 #random.randrange(-1300, -550) # display_height * (-1) # to give more space for obstacle to fully render\n","        self.speed = 40\n","        self.height = 100 # self.display_width / 8\n","        self.width = 100 # self.display_width / 6\n","        self.display_width = display_width\n","        self.display_height = display_height\n","        self.gameDisplay = gameDisplay\n","        self.img = pygame.image.load('images/asteroid.png').convert() \n","        self.img = pygame.transform.scale(self.img, (int(self.display_width*0.16),int(self.display_height*0.2)))\n","        #self.img = pygame.transform.scale(self.img, (int(self.display_width*0.08),int(self.display_height*0.1)))\n","\n","    def reset(self):\n","        self.x = random.randrange(0, self.display_width)\n","        self.y = 0 - self.height\n","\n","    def update(self):\n","        self.y += self.speed\n","\n","    def draw(self):\n","        self.gameDisplay.blit(self.img, (self.x,self.y))"],"metadata":{"id":"SXmOk9NHFzMW","executionInfo":{"status":"ok","timestamp":1658418859499,"user_tz":420,"elapsed":155,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Environment class\n","\n","def pre_processing(image, w=84, h=84):\n","    image = image[:800, 20:, :] # crop out the top so score is not visible\n","    #cv2.imwrite(\"original.jpg\", image)\n","    image = cv2.cvtColor(cv2.resize(image, (w, h)), cv2.COLOR_BGR2GRAY)\n","    #cv2.imwrite(\"color.jpg\", image)\n","    _, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n","    #cv2.imwrite(\"bw.jpg\", image)\n","\n","    a = np.array(image[None, :, :]).astype(np.float32) \n","    #a = image[None, :, :].astype(np.uint8) # use for open ai baselines\n","    a = a / 255 # normalise the outputs # do not use for open ai gym\n","\n","    return a #image[None, :, :].astype(np.float32)\n","\n","\n","class DroneWars(gym.Env):\n","    def __init__(self, gameDisplay, display_width=800, display_height=600, clock=None, fps = 30, *args, **kwargs):\n","        super(DroneWars, self).__init__()\n","        self.my_drone1 = Drone(gameDisplay)\n","        self.my_drone1.x = display_width * 0.8\n","        self.my_drone1.y = display_height * 0.85 #\n","        self.my_drone2 = Drone(gameDisplay)\n","        self.my_drone2.x = display_width * 0.2\n","        self.my_drone2.y = display_height * 0.85 # 500\n","        self.gameDisplay = gameDisplay\n","        self.display_width = display_width\n","        self.display_height = display_height\n","        self.score = 0\n","        self.gameExit = False\n","        self.clock = clock\n","        self.fps = fps\n","        self.black = (0,0,0)\n","        self.white = (255,255,255)\n","        self.dark_red = (150,0,0)\n","        self.green = (0,255,0)\n","        self.dark_green = (0,150,0)\n","        self.red = (255,0,0)\n","        self.obstacle_list = []\n","        self.n_actions = 9 # 3 actions per drone so it's 3^3 action space\n","        self.action_space = spaces.Discrete(self.n_actions)\n","        self.observation_space = spaces.Box(low=0, high=255, shape=(1, 84, 84), dtype=np.float32)\n","        #self.observation_space = spaces.Box(low=0, high=255, shape=(1,84,84), dtype=np.uint8) #needed for cnn policy for open baselines\n","        self.num_of_obstacles = 1 # nuber of obstacles\n","        \n","        for n in range(0,self.num_of_obstacles):\n","            self.obstacle_list.append(Obstacle(gameDisplay))\n","\n","        pygame.display.set_caption('Drone Wars')\n","        \n","\n","    def close(self):\n","        pass\n","\n","\n","    def reset(self):\n","        #r = np.zeros((1,84,84)).astype(np.float32) # use for custom model\n","        r = np.zeros((1,84,84)).astype(np.uint8) # use for openbaselines\n","        return r\n","\n","\n","    def render(self):\n","        self.gameDisplay.fill(self.white) # Comment this out if using scrolBackground\n","        for obs in self.obstacle_list:\n","            obs.draw()\n","            \n","        self.my_drone1.draw()\n","        self.my_drone2.draw()\n","\n","        self.scoreboard(self.score)\n","        pygame.display.update()\n","\n","\n","    def scoreboard(self, count):\n","        font = pygame.font.SysFont(None, 25)\n","        text = font.render(\"Score: \"+str(count), True, self.black)\n","        self.gameDisplay.blit(text,(0,0))\n","\n","\n","    def out_of_bounds(self, drone, display_width, display_height):\n","        if (drone.x > display_width - drone.drone_width or drone.x < 0) or \\\n","            (drone.y > display_height - drone.drone_height or drone.y < 0):\n","            \n","            return True \n","\n","\n","    def collision_multi(self, drone, obstacle_list):\n","        for obs in obstacle_list:\n","            if (drone.y < obs.y + obs.height):\n","\n","                if (drone.x > obs.x\n","                    and drone.x < obs.x + obs.width or drone.x + drone.drone_width > obs.x \n","                    and drone.x + drone.drone_width < obs.x + obs.width):\n","                    \n","                    return True   \n","\n","\n","    def collision(self, drone, obstacle):\n","            if (drone.y < obstacle.y + obstacle.height):\n","\n","                if (drone.x > obstacle.x\n","                    and drone.x < obstacle.x + obstacle.width or drone.x + drone.drone_width > obstacle.x \n","                    and drone.x + drone.drone_width < obstacle.x + obstacle.width):\n","                    \n","                    return True   \n","\n","\n","    def step(self, action, record=False): # 0: do nothing, 1: go left, 2: go right\n","        reward = 0.1\n","        \n","        if action == 0:\n","            #pass\n","            #print(\"Action: 0, do nothing\")\n","            reward += 0.01\n","            \n","        if action == 1:\n","            # drone1 do nothing, drone2 move left\n","            #print(\"Action: 1, drone2 left\")\n","            self.my_drone2.move_left()\n","            \n","        if action == 2:\n","            #drone 1 do nothing, drone 2 move right\n","            #print(\"Action: 2, drone2 right\")\n","            self.my_drone2.move_right()\n","        \n","        if action == 3:\n","            #drone 1 & 2 move left\n","            #print(\"Action: 3, drone1 left, drone2 move left\")\n","            self.my_drone1.move_left()\n","            self.my_drone2.move_left()\n","\n","        if action == 4:\n","            #drone 1 move left, drone 2 do nothing\n","            #print(\"Action: 4, drone1 left\")\n","            self.my_drone1.move_left()\n","\n","        if action == 5:\n","            #drone 1 move left, drone 2 move right\n","            #print(\"Action: 3, drone1 left, drone2 move right\")\n","            self.my_drone1.move_left()\n","            self.my_drone2.move_right()\n","\n","        if action == 6:\n","            #drone 1&2 move right\n","            #print(\"Action: 6, drone1 right, drone2 move right\")\n","            self.my_drone1.move_right()\n","            self.my_drone2.move_right()\n","\n","        if action == 7:\n","            #drone 1 move right, drone 2 do nothing\n","            #print(\"Action: 7, drone1 right\")\n","            self.my_drone1.move_right()\n","\n","        if action == 8:\n","            #print(\"Action: 8, drone1 right, drone2 move left\")\n","            self.my_drone1.move_right()\n","            self.my_drone2.move_left()\n","            # drone 1 move right, drone 2 move left\n","        \n","        \n","        # Uncomment bellow for single drone actions\n","        \"\"\"\n","        if action == 0:\n","            pass\n","        #    reward += 0.01\n","\n","        elif action == 1:\n","            self.my_drone1.move_left()\n","\n","        elif action == 2:\n","            self.my_drone1.move_right()\n","        \"\"\"\n","        \n","        # Update drone 1 & 2 position \n","        self.my_drone1.update()\n","        self.my_drone2.update()\n","\n","        # Update obstacle position. Move obstacle down the screen.\n","        for obs in self.obstacle_list:\n","            obs.update()\n","\n","        # Detect if obstacle went to the bottom of the screen, then reset y & x coordinates to start from the top again at a random x coordinate. \n","        for obs in self.obstacle_list:\n","            if obs.y > self.display_height:\n","                obs.reset()\n","                reward = 1\n","                self.score += 1\n","\n","        # Detect if drone1 left the display bounds, then game over\n","        if self.out_of_bounds(self.my_drone1, self.display_width, self.display_height):\n","            reward = -1\n","            self.gameExit = True\n","\n","        if self.out_of_bounds(self.my_drone2, self.display_width, self.display_height):\n","            #crash()\n","            reward = -1\n","            self.gameExit = True\n","\n","        # Detect when obstacle collides with the drone1 and reduce the score \n","        if self.collision_multi(self.my_drone1, self.obstacle_list):\n","            self.score -= 1 \n","            reward = -1\n","            self.gameExit = True\n","\n","        # Detect when obstacle collides with the drone2 and reduce the score \n","        if self.collision_multi(self.my_drone2, self.obstacle_list):\n","            self.score -= 1 \n","            reward = -1\n","            self.gameExit = True\n","\n","        self.render()\n","        self.clock.tick(self.fps) \n","        #print(\"clock:\", self.clock.get_fps()) # Uncomment to printout actual fps \n","        #print(\"fps\", self.fps) \n","\n","        if self.gameExit:\n","            self.__init__(self.gameDisplay, self.display_width, self.display_height, self.clock, self.fps)\n","        \n","        state = pygame.display.get_surface() \n","        state = array3d(state)\n","       \n","        done = (not (reward > 0))\n","        info = {}\n","\n","        # Return\n","        if record:\n","            #return pre_processing(state), np.transpose(cv2.cvtColor(state, cv2.COLOR_RGB2BGR), (1, 0, 2)), reward, done, info # Use for openbaselines\n","            return torch.from_numpy(pre_processing(state)), np.transpose(cv2.cvtColor(state, cv2.COLOR_RGB2BGR), (1, 0, 2)), reward, done, info \n","        else:\n","            #return pre_processing(state), reward, done, info # use for gym baselines\n","            return torch.from_numpy(pre_processing(state)), reward, done, info \n"],"metadata":{"id":"CG2WqZpsFmbx","executionInfo":{"status":"ok","timestamp":1658418990576,"user_tz":420,"elapsed":530,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class DeepQNetwork(nn.Module):\n","    def __init__(self):\n","        super(DeepQNetwork, self).__init__()\n","\n","        self.conv1 = nn.Sequential(nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True))\n","        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True))\n","        self.conv3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(inplace=True))\n","\n","        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 64, 512), nn.ReLU(inplace=True)) # orig\n","        self.fc2 = nn.Linear(512, 9)\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                nn.init.uniform_(m.weight, -0.01, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, input):\n","        output = self.conv1(input)\n","        output = self.conv2(output)\n","        output = self.conv3(output)\n","        output = output.view(output.size(0), -1)\n","        output = self.fc1(output)\n","        output = self.fc2(output)\n","\n","        return output"],"metadata":{"id":"-ZXjWkWiSk3q","executionInfo":{"status":"ok","timestamp":1658419117034,"user_tz":420,"elapsed":206,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Train custom Network\n","\n","# TODO:\n","# Implement Hindsight Experience Replay or similar\n","# Training works well for a single drone but strugles for 2 drones\n","\n","# Model parameters\n","model_params = {\n","    'batch_size' : 32, \n","    'optimizer' : \"adam\", # [\"sgd\", \"adam\"]\n","    'lr' : 1e-4,\n","    'gamma' : 0.99,\n","    'initial_epsilon' : 1,\n","    'final_epsilon' : 0.001,\n","    'num_decay_iters' : 500000,\n","    'num_iters' : 650000,\n","    'replay_memory_size' : 100000, # Replay memory size must not exeed available RAM # 10000 = 1Gb\n","    'saved_folder' : \"model\",\n","    'render' : True \n","}\n","\n","def train(model_params):\n","    \n","    pygame.init()\n","    clock = pygame.time.Clock()\n","    #flags = pygame.SHOWN # Use this pygame flag for training on local machine to see game rendering\n","    flags = pygame.HIDDEN \n","    gameDisplay = pygame.display.set_mode((800,600), flags) \n","    tau = 1 # required for polyak update for openbaselines\n","    update_starts = 1 # num of steps after when to start training the target network\n","    updated = False \n","    model_update_rate = 5 # update target network after number of episodes\n","    episodes = 0 \n","    rewards = []\n","    scores = []\n","    all_scores = np.array(1)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(123)\n","    else:\n","        torch.manual_seed(123)\n","\n","    model = DeepQNetwork() \n","    model_target = DeepQNetwork()\n","    # read more https://blog.gofynd.com/building-a-deep-q-network-in-pytorch-fa1086aa5435\n","\n","    if torch.cuda.is_available():\n","        model.cuda()\n","        model_target.cuda()\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr= model_params['lr'])\n","    optimizer_target = torch.optim.Adam(model_target.parameters(), lr= model_params['lr'])\n","\n","    if not os.path.isdir(model_params['saved_folder']):\n","        os.makedirs(model_params['saved_folder'])\n","    checkpoint_path = os.path.join(model_params['saved_folder'], \"drone_wars.pth\")\n","    checkpoint_path_target = os.path.join(model_params['saved_folder'], \"drone_wars_target.pth\")\n","    memory_path = os.path.join(model_params['saved_folder'], \"replay_memory.pkl\")\n","\n","    # Check if model exists in path and continue training from last step\n","    if os.path.isfile(checkpoint_path):\n","        checkpoint = torch.load(checkpoint_path)\n","        checkpoint_target = torch.load(checkpoint_path_target)\n","        iter = checkpoint[\"iter\"] + 1\n","        model.load_state_dict(checkpoint[\"model_state_dict\"])\n","        model_target.load_state_dict(checkpoint[\"model_state_dict\"])\n","        #model_target.load_state_dict(checkpoint_target[\"model_state_dict\"])\n","        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","        #optimizer_target.load_state_dict(checkpoint_target[\"optimizer\"])\n","        print(\"Load trained model from iteration {}\".format(iter))\n","    else:\n","        iter = 0\n","    \n","    if os.path.isfile(memory_path):\n","        with open(memory_path, \"rb\") as f:\n","            replay_memory = pickle.load(f)\n","        print(\"Load replay memory\")\n","    else:\n","        replay_memory = []\n","    #criterion = nn.MSELoss() # Mean square error loss\n","    criterion = nn.SmoothL1Loss() # stablebaselines dqn is using huber loss\n","\n","    env = DroneWars(gameDisplay, display_width=800, display_height=600, clock=clock, fps=200)\n","\n","    state, _, _, _ = env.step(0)\n","    state = torch.cat(tuple(state for _ in range(4)))[None, :, :, :] # coppies same state over for 4 times\n","    # [None, :, :, :] doesnt do anything...\n","    # uses 4 channels, coppies sames state info 4 times? # can change in nn to 2 channels\n","    \n","    \"\"\"\n","    a = np.eye(9, dtype=int)\n","    actions = {}\n","    for n in range(9):\n","        actions[n] = a[n]\n","    \"\"\"\n","    # multiple drones\n","    action_dict = {\n","        0 : [1,0,0,0,0,0,0,0,0],\n","        1 : [0,1,0,0,0,0,0,0,0], \n","        2 : [0,0,1,0,0,0,0,0,0],\n","        3 : [0,0,0,1,0,0,0,0,0],\n","        4 : [0,0,0,0,1,0,0,0,0], \n","        5 : [0,0,0,0,0,1,0,0,0],\n","        6 : [0,0,0,0,0,0,1,0,0],\n","        7 : [0,0,0,0,0,0,0,1,0],\n","        8 : [0,0,0,0,0,0,0,0,1] \n","    }\n","    \"\"\"\n","    # one drone\n","    action_dict = {\n","        0 : [1,0,0],\n","        1 : [0,1,0], \n","        2 : [0,0,1],\n","    }\n","    \"\"\"\n","    while iter < model_params['num_iters']:\n","\n","        if torch.cuda.is_available():\n","            #prediction = model(state.cuda())[0]\n","            if iter > update_starts:\n","                prediction = model_target(state.cuda())[0]\n","            else:\n","                prediction = model(state.cuda())[0]\n","        else:\n","            #prediction = model(state)[0]\n","            #prediction = model_target(state)[0]\n","            if iter > update_starts:\n","                prediction = model_target(state)[0]\n","            else:\n","                prediction = model(state)[0]\n","                \n","        # Exploration or exploitation\n","        epsilon = model_params['final_epsilon'] + (\n","                max(model_params['num_decay_iters'] - iter, 0) * (model_params['initial_epsilon'] - model_params['final_epsilon']) / model_params['num_decay_iters'])\n","        \n","        u = random.random()\n","        random_action = u <= epsilon\n","\n","        if random_action:\n","            #action = random.randint(0, 2) # single drone\n","            action = random.randint(0, 8)\n","        else:\n","            action = torch.argmax(prediction).item()\n","\n","        next_state, reward, done, _ = env.step(action)\n","\n","        next_state = torch.cat((state[0, 1:, :, :], next_state))[None, :, :, :]\n","\n","        replay_memory.append([state, action, reward, next_state, done])\n","        \n","\n","        if len(replay_memory) > model_params['replay_memory_size']:\n","            del replay_memory[0]\n","        \n","        batch = random.sample(replay_memory, min(len(replay_memory), model_params['batch_size']))\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n","\n","        state_batch = torch.cat(tuple(state for state in state_batch))\n","\n","        action_batch = torch.from_numpy(np.array([action_dict[action] for action in action_batch], dtype=np.float32))\n","\n","        reward_batch = torch.from_numpy(np.array(reward_batch, dtype=np.float32)[:, None])\n","        next_state_batch = torch.cat(tuple(state for state in next_state_batch))\n","\n","        if torch.cuda.is_available():\n","            state_batch = state_batch.cuda()\n","            action_batch = action_batch.cuda()\n","            reward_batch = reward_batch.cuda()\n","            next_state_batch = next_state_batch.cuda()\n","        \n","        #current_prediction_batch = model(state_batch)\n","        #next_prediction_batch = model(next_state_batch)\n","\n","        if iter > update_starts: \n","            current_prediction_batch = model_target(state_batch)\n","            next_prediction_batch = model_target(next_state_batch)\n","        else: \n","            current_prediction_batch = model(state_batch)\n","            next_prediction_batch = model(next_state_batch)\n","\n","        y_batch = torch.cat(\n","            tuple(reward if done else reward + model_params['gamma'] * torch.max(prediction) for reward, done, prediction in\n","                  zip(reward_batch, done_batch, next_prediction_batch)))\n","\n","        q_value = torch.sum(current_prediction_batch * action_batch, dim=1)\n","        optimizer.zero_grad()\n","        loss = criterion(q_value, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        state = next_state\n","        \n","        # Keeping score list\n","        score = env.score\n","        iter += 1\n","        rewards.append(reward)\n","        scores.append(score)\n","        all_scores = np.append(all_scores, score)\n","\n","        \n","        # Increment episode if done\n","        if done:\n","            episodes += 1\n","            updated = False\n"," \n","        if iter < update_starts and done:\n","            print(f\"# Collecting samples for {iter+1}/{update_starts} steps #\")\n","            print(f\"Episode: {episodes}\")\n","            print()\n","\n","        # Update target network every 5 episodes\n","        if (iter > update_starts) and ((episodes) % model_update_rate == 0) and (updated == False): \n","            polyak_update(model.parameters(), model_target.parameters(), tau)\n","            updated = True\n","            \n","            print(\"###############################\")\n","            print(\"### Updating target network ###\")\n","            print(\"###############################\")\n","            \n","            print(f\"Episode: {episodes}\")\n","            print(f\"Step: {iter+1}/{model_params['num_iters']}\")\n","            print(f\"Loss: {loss:.5f}\")\n","            print(f\"LR: {optimizer.param_groups[0]['lr']:.5f}\")\n","            print(f\"Epsilon: {epsilon:.4f}\")\n","            print(f\"Mean Reward: {np.mean(rewards):.4f}\")\n","            print(f\"Mean Score: {np.mean(scores):.4f}\")\n","            print()\n","            \n","            rewards = []\n","            scores = []\n","\n","        # Save model\n","        if (iter + 1) % 5000 == 0:\n","            checkpoint = {\"iter\": iter,\n","                          \"model_state_dict\": model.state_dict(),\n","                          \"optimizer\": optimizer.state_dict()}\n","            torch.save(checkpoint, checkpoint_path)\n","\n","            checkpoint_target = {iter: iter, \n","                            \"model_state_dict\": model_target.state_dict(),\n","                            \"optimizer\": optimizer_target.state_dict()}\n","            torch.save(checkpoint_target, checkpoint_path_target)\n","\n","            print(\"## Saving model. Average Score: \", np.mean(all_scores))\n","            all_scores = np.array(1) # Reset all_scores list\n","\n","            with open(memory_path, \"wb\") as f:\n","                pickle.dump(replay_memory, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","\n"],"metadata":{"id":"ERISZT7MSPob","executionInfo":{"status":"ok","timestamp":1658420395937,"user_tz":420,"elapsed":660,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["train(model_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"f_n5FMK6Y-3O","executionInfo":{"status":"error","timestamp":1658420402929,"user_tz":420,"elapsed":3214,"user":{"displayName":"Mantas Gribulis","userId":"11078549842196209560"}},"outputId":"2cbdce7a-d14d-4ef8-92e4-b19f98d4cefa"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["###############################\n","### Updating target network ###\n","###############################\n","Episode: 0\n","Step: 3/650000\n","Loss: 0.00502\n","LR: 0.00010\n","Epsilon: 1.0000\n","Mean Reward: 0.1000\n","Mean Score: 0.0000\n","\n","###############################\n","### Updating target network ###\n","###############################\n","Episode: 5\n","Step: 84/650000\n","Loss: 0.02059\n","LR: 0.00010\n","Epsilon: 0.9998\n","Mean Reward: 0.0444\n","Mean Score: 0.1605\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-123ccd22ff12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-44-380de4e2abf5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_params)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m#prediction = model(state.cuda())[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mupdate_starts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}